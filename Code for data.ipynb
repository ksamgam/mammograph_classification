{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import mahotas as mt\n",
    "\n",
    "from PIL import Image \n",
    "from skimage import io \n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border \n",
    "from skimage.morphology import remove_small_objects \n",
    "from skimage.morphology import binary_closing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImages(img): \n",
    "    # Resize image to 750 x 375\n",
    "    img = cv2.resize(orig_img, dsize = (375,750), interpolation=cv2.INTER_NEAREST)\n",
    "    img = resize_img.astype('float32')\n",
    "\n",
    "    # Normalize images using max-min\n",
    "    normalize_img = np.divide(np.subtract(resize_img, np.min(resize_img)),\n",
    "                              np.subtract(np.max(resize_img ), np.min(resize_img)))\n",
    "\n",
    "    # Standardize image using z-score and adding constant to make positive arrays \n",
    "    scaled_img = np.divide(np.subtract(normalize_img, np.mean(normalize_img)),\n",
    "                           np.std(normalize_img))\n",
    "    scaled_img += abs(np.amin(scaled_img))\n",
    "    return scaled_img \n",
    "    \n",
    "def segmentAndSmooth(img): \n",
    "    #Otsu's Threshold \n",
    "    oned_img = img.ravel()\n",
    "    nonzero_oned = oned_img[oned_img > 0]\n",
    "    thresh = threshold_otsu(nonzero_oned)\n",
    "    image = scaled_img > thresh \n",
    "    \n",
    "    #Filtering and Smoothing \n",
    "    labeled_img = skimage.measure.label(image, neighbors=8)\n",
    "    filtered_img = remove_small_objects(labeled_img, min_size=0.1, connectivity=8)\n",
    "    smoothed_img = binary_closing(filtered_img)\n",
    "    return smoothed_img \n",
    "\n",
    "def featureExtraction(normalizedImg, smoothedImg): \n",
    "    features = []\n",
    "    textures = mt.features.haralick(smoothedImg)\n",
    "    hu_moments = cv2.HuMoments(cv2.moments(normalizedImg)).flatten()\n",
    "    ht_mean = textures.mean(axis=0)\n",
    "    features = np.concatenate([hu_moments,ht_mean])\n",
    "    return features\n",
    "\n",
    "def textureExtractionOnly(smoothedImg): \n",
    "    features = []\n",
    "    textures = mt.features.haralick(smoothedImg)\n",
    "    ht_mean = textures.mean(axis=0)\n",
    "    return ht_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading in the images from the 20GB of data downloaded \n",
    "scans_path = \"/Users/arelivalencia/Desktop/Images\" \n",
    "list_of_scans = os.listdir(scans_path)\n",
    "\n",
    "num_of_scans = len(list_of_scans)\n",
    "allData = np.zeros((281270,num_of_scans))\n",
    "\n",
    "for scan_num in range(len(list_of_scans)):\n",
    "    scan_path = os.path.join(scans_path, list_of_scans[scan_num])\n",
    "    image = io.imread(scan_path)\n",
    "    \n",
    "    normalizedImg = normalizeImages(image)\n",
    "    smoothedImg = segmentAndSmooth(normalizedImg)\n",
    "    features = featureExtraction(normalizedImg, smoothedImg)\n",
    "    \n",
    "    imgFlattened = normalizedImg.flatten()\n",
    "    img_Features = np.concatenate([imgFlattened,features])\n",
    "    \n",
    "    allData[:,scan_num] = img_Features\n",
    "\n",
    "np.savetxt(\"allData.csv\", allData, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading in the images from the 20GB of data downloaded \n",
    "scans_path = \"/Users/arelivalencia/Desktop/Images\" \n",
    "list_of_scans = os.listdir(scans_path)\n",
    "\n",
    "num_of_scans = len(list_of_scans)\n",
    "data_Textures = np.zeros((281263,num_of_scans))\n",
    "\n",
    "for scan_num in range(len(list_of_scans)):\n",
    "    scan_path = os.path.join(scans_path, list_of_scans[scan_num])\n",
    "    image = io.imread(scan_path)\n",
    "    \n",
    "    normalizedImg = normalizeImages(image)\n",
    "    smoothedImg = segmentAndSmooth(normalizedImg)\n",
    "    textures = textureExtractionOnly(smoothedImg)\n",
    "    \n",
    "    imgFlattened = normalizedImg.flatten()\n",
    "    img_Features = np.concatenate([imgFlattened,textures])\n",
    "                      \n",
    "    data_Textures[:,scan_num] = img_Features\n",
    "\n",
    "np.savetxt(\"Data with images and Harlick textures - no shape features.csv\", data_Textures, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
